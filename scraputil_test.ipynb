{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# from scraputil import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\public\\aci_proj\\projects\\bd-newspaper-scrapper\\venv\\lib\\site-packages\\past\\builtins\\misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "c:\\users\\public\\aci_proj\\projects\\bd-newspaper-scrapper\\venv\\lib\\site-packages\\gensim\\matutils.py:22: DeprecationWarning: Please use `triu` from the `scipy.linalg` namespace, the `scipy.linalg.special_matrices` namespace is deprecated.\n",
      "  from scipy.linalg.special_matrices import triu\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shadm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping from ntv!\n",
      "News number 1: ঢাকায় নিয়োগ দেবে এসিআই\n",
      "News number 2: নারায়ণগঞ্জে নিয়োগ দেবে এসিআই ফার্মাসিউটিক্যালস\n",
      "News number 3: এসিআই ফার্মাসিউটিক্যালসে চাকরির সুযোগ\n",
      "News number 4: মানিকগঞ্জে নিয়োগ দেবে এসিআই মোটরস\n",
      "News number 5: ডিপ্লোমা পাসে নিয়োগ দেবে এসিআই মোটরস\n",
      "News number 6: ডিপ্লোমা পাসে নিয়োগ দেবে এসিআই\n",
      "News number 7: স্নাতক পাসে নিয়োগ দেবে এসিআই\n",
      "News number 8: ঢাকায় নিয়োগ দেবে এসিআই\n",
      "News number 9: গাজীপুরে ইন্টার্ন করার সুযোগ দেবে এসিআই ফরমুলেসনস\n",
      "News number 10: এসএসসি পাসে নিয়োগ দেবে এসিআই\n",
      "News number 11: ঢাকায় স্নাতক পাসে নিয়োগ দেবে এসিআই\n",
      "News number 12: বসুন্ধরা গ্রুপে চাকরির সুযোগ\n",
      "News number 13: ঢাকায় নিয়োগ দেবে এপিক গ্রুপ\n",
      "News number 14: স্নাতক পাসে সজীব গ্রুপে চাকরির সুযোগ\n",
      "News number 15: সারা দেশে নিয়োগ দেবে ল্যাবএইড, থাকতে হবে ভ্রমণের মানসিকতা\n",
      "News number 16: ক্যারিয়ার গড়ুন যমুনা গ্রুপে\n",
      "News number 17: চট্টগ্রামে নিয়োগ দেবে এস. আলাম গ্রপ\n",
      "News number 18: নিয়োগ দেবে বাংলাদেশ পল্লী উন্নয়ন বোর্ড\n",
      "News number 19: ক্যারিয়ার গড়ুন বসুন্ধরা গ্রুপে\n",
      "News number 20: NTV: Latest Bangla News, Infotainment, Online & Live TV\n",
      "News number 21: সারা দেশে নিয়োগ দেবে কাজী ফার্মস\n",
      "News number 22: স্নাতক পাসে নিয়োগ দেবে রহিমআফরোজ\n",
      "News number 23: স্নাতক পাসে নিয়োগ দেবে এসিআই\n",
      "News number 24: সারা দেশে নিয়োগ দেবে এসিআই মোটরস\n",
      "News number 25: ডিপ্লোমা পাসে নিয়োগ দেবে এসিআই\n",
      "News number 26: স্নাতক পাসে নিয়োগ দেবে এসিআই\n",
      "News number 27: স্নাতক পাসে নিয়োগ দেবে এসিআই\n",
      "News number 28: সিরাজগঞ্জে নিয়োগ দেবে এসিআই\n",
      "News number 29: এসএসসি পাসে চাকরি দেবে এসিআই\n",
      "News number 30: স্নাতক পাসে নিয়োগ দেবে এসিআই মটরস\n",
      "News number 31: স্নাতক পাসে নিয়োগ দেবে এসিআই, সাপ্তাহিক ছুটি দুদিন\n",
      "News number 32: সিরাজগঞ্জে চাকরি দেবে এসিআই\n",
      "News number 33: নিয়োগ দেবে এসিআই মোটরস\n",
      "News number 34: অভিজ্ঞতা ছাড়াই নিয়োগ দেবে এসিআই মোটরস\n",
      "News number 35: ডিপ্লোমা পাসে এসিআই’তে চাকরির সুযোগ\n",
      "News number 36: নতুনদের চাকরি দিচ্ছে এসিআই গ্রুপ\n",
      "News number 37: ঢাকার গুলশানে নিয়োগ দেবে এসিআই\n",
      "News number 38: ঢাকায় নিয়োগ দেবে এসিআই মোটরস\n",
      "News number 39: মেডিকেল সার্ভিস অফিসার পদে লোক নেবে এসিআই\n",
      "News number 40: এইচএসসি পাসে নিয়োগ দেবে পাঞ্জেরী পাবলিকেশন\n",
      "News number 41: সিসিমপুরের গণমাধ্যম পরামর্শক হলেন শিশুসাহিত্যিক পলাশ মাহবুব\n",
      "News number 42: ফিল্ড মার্কেটিং এক্সিকিউটিভ পদে ক্যারিয়ার গড়ুন\n",
      "News number 43: বিভিন্ন জেলায় নিয়োগ দেবে রূপায়ণ গ্রুপ\n",
      "News number 44: নতুনদের নিয়োগ দেবে শপআপ\n",
      "News number 45: ইউএস-বাংলা এয়ারলাইন্সে চাকরি, থাকছে বিনামূল্যে বিমান ভ্রমণের সুযোগ\n",
      "News number 46: টেন মিনিট স্কুলে চাকরির সুযোগ, বেতন ৫০ হাজার টাকা\n",
      "News number 47: নিয়োগ দেবে যমুনা টেলিভিশন\n",
      "News number 48: কক্সবাজারে এসএসসি পাসে নিয়োগ দেবে আজকেরডিল ডটকম\n",
      "News number 49: একাধিক পদে নিয়োগ দেবে এয়ার অ্যাস্ট্রা\n",
      "News number 50: সারা দেশে নিয়োগ দেবে কেয়ার নিউট্রিশন\n",
      "News number 51: সারা দেশে নিয়োগ দেবে বেক্সিমকো কমিউনিকেশনস\n",
      "News number 52: কুমিল্লায় নিয়োগ মেরী স্টোপস\n",
      "News number 53: এসএসসি পাসে চাকরির সুযোগ সিটি গ্রুপে\n",
      "News number 54: স্নাতক পাসে নিয়োগ দেবে সোয়ান গ্রুপ\n",
      "News number 55: ওয়ালটন ডিজি-টেক ইন্ডাস্ট্রিজে চাকরির সুযোগ, বেতন ৩০ হাজার টাকা\n",
      "News number 56: স্নাতক পাসে নিয়োগ দেবে আমিন মোহাম্মদ গ্রুপ\n",
      "News number 57: ডিপ্লোমা পাসে নিয়োগ দেবে ব্যুরো বাংলাদেশ\n",
      "News number 58: স্নাতক পাসে নিয়োগ দেবে জেমকন সিটি\n",
      "News number 59: বিভিন্ন জেলায় পার্ট টাইম চাকরির সুযোগ দেবে আড়ং\n",
      "News number 60: নিয়োগ দেবে ওয়াটার এইড বাংলাদেশ, বেতন ৮৭ হাজার টাকা\n",
      "News number 61: সারা দেশে নিয়োগ দেবে প্রাণ আরএফএল গ্রুপ\n",
      "News number 62: গ্রাম উন্নয়ন কেন্দ্রে চাকরির সুযোগ, বেতন ৩১ হাজার টাকা\n",
      "News number 63: গাজীপুরে নিয়োগ দেবে ডিবিএল গ্রুপ\n",
      "News number 64: স্নাতক পাসে কনফিডেন্স গ্রুপে চাকরির সুযোগ\n",
      "News number 65: ঢাকায় নিয়োগ দেবে আকিজ ফুড অ্যান্ড বেভারেজ\n",
      "News number 66: নিয়োগ দেবে গণ উন্নয়ন কেন্দ্র, বেতন ৫৬ হাজার টাকা\n",
      "News number 67: স্নাতক পাসে নিয়োগ দেবে এসকিউ গ্রুপ\n",
      "News number 68: এস. আলম গ্রপে চাকরির সুযোগ, কর্মস্থল ঢাকা\n",
      "News number 69: ঢাকায় নিয়োগ দেবে আদ্-দ্বীন উইমেন্স মেডিকেল কলেজ\n",
      "News number 70: অভিজ্ঞতা ছাড়াই প্রিমিয়ার ব্যাংকে চাকরি, বেতন ১৫ হাজার টাকা\n",
      "News number 71: স্নাতক পাসে নিয়োগ দেবে আনোয়ার সিমেন্ট শিট\n",
      "News number 72: ৩১ জনকে নিয়োগ দেবে বিশ্বসাহিত্য কেন্দ্র\n",
      "News number 73: মার্কেন্টাইল ব্যাংকে চাকরির সুযোগ, বেতন ২৮ হাজার টাকা\n",
      "News number 74: গাজীপুরে চাকরি দেবে পলমল গ্রুপ অব ইন্ডাস্ট্রিজ\n",
      "News number 75: বাসা ও অফিসে বসে কাজের সুযোগ, বেতন ১২ হাজার টাকা\n",
      "News number 76: নারায়ণগঞ্জে নিয়োগ দেবে মেঘনা গ্রুপ অব ইন্ডাস্ট্রিজ\n",
      "News number 77: স্টাফ রিপোর্টার নিয়োগ দেবে মাছরাঙ্গা টেলিভিশন\n",
      "News number 78: নতুনদের জন্য আবুল খায়ের গ্রুপে ১৮ হাজার টাকার চাকরি\n",
      "News number 79: এইচএসসি পাসেই নিয়োগ দেবে প্রাণ গ্রুপ\n",
      "News number 80: নিয়োগ দেবে চালডাল লিমিটেড, বেতন ২২ হাজার টাকা\n",
      "News number 81: ডিপ্লোমা পাসে নিয়োগ দেবে বসুন্ধরা গ্রুপ\n",
      "News number 82: সারা দেশে নিয়োগ দেবে এলিট পেইন্ট\n",
      "News number 83: চার শতাধিক কর্মী নিয়োগ দেবে যমুনা গ্রুপ\n",
      "News number 84: নিয়োগ দেবে ব্যাংক এশিয়া, বেতন ৩৫ হাজার টাকা\n",
      "News number 85: বিভিন্ন পদে নিয়োগ দিচ্ছে কাজী ফার্মস গ্রুপ\n",
      "News number 86: ৫৫ হাজার টাকা বেতনে চাকরির সুযোগ\n",
      "News number 87: ইস্পাহানি গ্রুপে ২৫ হাজার টাকার চাকরি, সুযোগ পাচ্ছেন নতুনরাও\n",
      "News number 88: সিনিয়র এক্সিকিউটিভ পদে চাকরির সুযোগ\n",
      "News number 89: নতুনদের জন্য ব্রিটিশ আমেরিকান টোবাকোতে আকর্ষণীয় ক্যারিয়ার\n",
      "News number 90: এইচএসসি পাসে নাভানা ফার্মাসিউটিক্যালসে চাকরির সুযোগ, থাকছে অন্যান্য সুবিধা\n",
      "News number 91: নতুনদের নিয়োগ দেবে আবুল খায়ের সিরামিক ইন্ডাস্ট্রিজ\n",
      "News number 92: গাজীপুরে চাকরি দেবে আনোয়ার গ্রুপ অব ইন্ডাস্ট্রিজ\n",
      "News number 93: চাকরি দিচ্ছে হোটেল লা মেরিডিয়ান\n",
      "News number 94: আনোয়ার গ্রুপে চাকরির সুযোগ, থাকছে অন্যান্য সুযোগ-সুবিধা\n",
      "News number 95: বিভিন্ন পদে নিয়োগ দিচ্ছে স্কয়ার গ্রুপ\n",
      "News number 96: শোরুম ম্যানেজার হিসেবে ক্যারিয়ার গড়ুন\n",
      "News number 97: এইচএসসি পাসেই নিয়োগ দেবে বসুন্ধরা গ্রুপ\n",
      "News number 98: সৌদি আরবে নিয়োগ দেবে প্রাণ গ্রুপ\n",
      "News number 99: ঢাকায় নিয়োগ দেবে বেঙ্গল কমার্শিয়াল ব্যাংক\n",
      "News number 100: আকর্ষণীয় পদে তরুণদের চাকরি দিচ্ছে স্বপ্ন\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPU available\n",
      "Model already on device!\n",
      "NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "Memory Usage:\n",
      "Allocated: 1.6 GB\n",
      "Cached:    1.7 GB\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=108.0.5359.125)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00ABE563]\n\t(No symbol) [0x00A47FC1]\n\t(No symbol) [0x0093D04D]\n\t(No symbol) [0x00922D7A]\n\t(No symbol) [0x0098BE7B]\n\t(No symbol) [0x0099C196]\n\t(No symbol) [0x00988386]\n\t(No symbol) [0x0096163C]\n\t(No symbol) [0x0096269D]\n\tGetHandleVerifier [0x00D59B82+2658722]\n\tGetHandleVerifier [0x00D4CB84+2605476]\n\tGetHandleVerifier [0x00B6825A+620666]\n\tGetHandleVerifier [0x00B66E80+615584]\n\t(No symbol) [0x00A505EC]\n\t(No symbol) [0x00A55958]\n\t(No symbol) [0x00A55A45]\n\t(No symbol) [0x00A6050B]\n\tBaseThreadInitThunk [0x76EA7D69+25]\n\tRtlInitializeExceptionChain [0x77A1BB9B+107]\n\tRtlClearBits [0x77A1BB1F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNoSuchWindowException\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 26\u001B[0m\n\u001B[0;32m     23\u001B[0m news_data_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame()\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m NAMES[:\u001B[38;5;241m3\u001B[39m]:\n\u001B[1;32m---> 26\u001B[0m     news_df \u001B[38;5;241m=\u001B[39m \u001B[43mget_news\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgoogle_news\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m translate:\n\u001B[0;32m     28\u001B[0m         news_df \u001B[38;5;241m=\u001B[39m get_news\u001B[38;5;241m.\u001B[39mtranslate_news(news_df)\n",
      "File \u001B[1;32mC:\\Users\\Public\\ACI_Proj\\Projects\\BD-newspaper-scrapper\\scraputil.py:647\u001B[0m, in \u001B[0;36mGetNews.extract\u001B[1;34m(self, name, google_news, pages, keep_content)\u001B[0m\n\u001B[0;32m    644\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msearch_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn2en\u001B[38;5;241m.\u001B[39mtranslate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msearch_key) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnewspaper_map[\n\u001B[0;32m    645\u001B[0m                                                                name]\u001B[38;5;241m.\u001B[39mlanguage \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124men\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msearch_key\n\u001B[0;32m    646\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m google_news:\n\u001B[1;32m--> 647\u001B[0m     scraped_df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch_google_news\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_content\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    648\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    649\u001B[0m     scraped_df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnewspaper_map[name]\u001B[38;5;241m.\u001B[39mfn(pages, keep_content)\n",
      "File \u001B[1;32mC:\\Users\\Public\\ACI_Proj\\Projects\\BD-newspaper-scrapper\\scraputil.py:656\u001B[0m, in \u001B[0;36mGetNews.search_google_news\u001B[1;34m(self, name, keep_content)\u001B[0m\n\u001B[0;32m    653\u001B[0m extn \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m&hl=en-BD&gl=BD&ceid=BD:en\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnewspaper_map[name]\u001B[38;5;241m.\u001B[39mlanguage \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124men\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m&hl=bn&gl=BD&ceid=BD:bn\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    654\u001B[0m search_link \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://news.google.com/search?q=site:\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnewspaper_map[\n\u001B[0;32m    655\u001B[0m     name]\u001B[38;5;241m.\u001B[39mlink \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m20\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msearch_key \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m extn\n\u001B[1;32m--> 656\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdriver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43msearch_link\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    657\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mScraping from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    659\u001B[0m identifier \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m//article\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32mc:\\users\\public\\aci_proj\\projects\\bd-newspaper-scrapper\\venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:441\u001B[0m, in \u001B[0;36mWebDriver.get\u001B[1;34m(self, url)\u001B[0m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, url: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    438\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    439\u001B[0m \u001B[38;5;124;03m    Loads a web page in the current browser session.\u001B[39;00m\n\u001B[0;32m    440\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 441\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCommand\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mGET\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43murl\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\public\\aci_proj\\projects\\bd-newspaper-scrapper\\venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001B[0m, in \u001B[0;36mWebDriver.execute\u001B[1;34m(self, driver_command, params)\u001B[0m\n\u001B[0;32m    427\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_executor\u001B[38;5;241m.\u001B[39mexecute(driver_command, params)\n\u001B[0;32m    428\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response:\n\u001B[1;32m--> 429\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_handler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    430\u001B[0m     response[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_unwrap_value(\n\u001B[0;32m    431\u001B[0m         response\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    432\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[1;32mc:\\users\\public\\aci_proj\\projects\\bd-newspaper-scrapper\\venv\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001B[0m, in \u001B[0;36mErrorHandler.check_response\u001B[1;34m(self, response)\u001B[0m\n\u001B[0;32m    241\u001B[0m         alert_text \u001B[38;5;241m=\u001B[39m value[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124malert\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001B[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001B[39;00m\n\u001B[1;32m--> 243\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001B[1;31mNoSuchWindowException\u001B[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=108.0.5359.125)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00ABE563]\n\t(No symbol) [0x00A47FC1]\n\t(No symbol) [0x0093D04D]\n\t(No symbol) [0x00922D7A]\n\t(No symbol) [0x0098BE7B]\n\t(No symbol) [0x0099C196]\n\t(No symbol) [0x00988386]\n\t(No symbol) [0x0096163C]\n\t(No symbol) [0x0096269D]\n\tGetHandleVerifier [0x00D59B82+2658722]\n\tGetHandleVerifier [0x00D4CB84+2605476]\n\tGetHandleVerifier [0x00B6825A+620666]\n\tGetHandleVerifier [0x00B66E80+615584]\n\t(No symbol) [0x00A505EC]\n\t(No symbol) [0x00A55958]\n\t(No symbol) [0x00A55A45]\n\t(No symbol) [0x00A6050B]\n\tBaseThreadInitThunk [0x76EA7D69+25]\n\tRtlInitializeExceptionChain [0x77A1BB9B+107]\n\tRtlClearBits [0x77A1BB1F+191]\n"
     ]
    }
   ],
   "source": [
    "from scraputil import GetNews, get_sentiment\n",
    "\n",
    "NAMES = [ # 'newspapers71',\n",
    "         'ntv',\n",
    "         'prothomalo',\n",
    "         'kalerkantho',\n",
    "         'bhorerkagoj',\n",
    "         'jaijaidin',\n",
    "         # 'amadershomoy',\n",
    "         'inqilab',\n",
    "         'jugantor',\n",
    "         'nayadiganta',\n",
    "         # 'manabzamin',\n",
    "         'thedailystar',\n",
    "         'dhakatribune',\n",
    "         'tbsnews',\n",
    "         'thefinancialexpress']\n",
    "\n",
    "get_news = GetNews(browser='Chrome', headless=False, search_key=\"এসিআই\")\n",
    "get_news.select_browser('Chrome')\n",
    "\n",
    "translate = True\n",
    "news_data_df = pd.DataFrame()\n",
    "for name in NAMES[:3]:\n",
    "\n",
    "    news_df = get_news.extract(name, google_news=True, keep_content=True)\n",
    "    if translate:\n",
    "        news_df = get_news.translate_news(news_df)\n",
    "    news_df['sentiment'] = get_sentiment(news_df.headline.to_list())\n",
    "    news_data_df = pd.concat((news_data_df, news_df), axis=0, ignore_index=True)\n",
    "    # except:\n",
    "    #     news_data_df.to_csv(\"./data/temp1.csv\", index=False)\n",
    "\n",
    "get_news.close_browser()\n",
    "news_data_df.to_csv(\"./outputs.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# news = translate_news(news)\u001B[39;00m\n\u001B[0;32m      3\u001B[0m date \u001B[38;5;241m=\u001B[39m news\u001B[38;5;241m.\u001B[39mdate[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m----> 4\u001B[0m \u001B[43msingle_detection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapi_key\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m15c5418e83130ba091ea4d07875a7517\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\public\\aci_proj\\projects\\bd-newspaper-scrapper\\venv\\lib\\site-packages\\deep_translator\\detection.py:68\u001B[0m, in \u001B[0;36msingle_detection\u001B[1;34m(text, api_key, detailed, *args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m detailed:\n\u001B[0;32m     66\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m detections[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m---> 68\u001B[0m lang \u001B[38;5;241m=\u001B[39m \u001B[43mdetections\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlanguage\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m lang:\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lang\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "news = pd.read_csv(\"./data/all_newspaper_title.csv\")\n",
    "# news = translate_news(news)\n",
    "date = news.date[1]\n",
    "bn2en.translate(news_df.section[i])\n",
    "\n",
    "# single_detection(date, api_key=\"15c5418e83130ba091ea4d07875a7517\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import chromedriver_autoinstaller as cai\n",
    "cai.install()\n",
    "\n",
    "# driver = uc.Chrome(options=options)\n",
    "# driver.get(\"https://www.dhakatribune.com/\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "Timestamp('2022-09-06 00:00:00')"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(news_data_df['date'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import chromedriver_autoinstaller\n",
    "from selenium.webdriver.common.by import By\n",
    "chromedriver_autoinstaller.install()\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"start-maximized\")\n",
    "search_key=\"এসিআই\"\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get('https://news.google.com/search?q=site:https://www.ntvbd.com%20%22%E0%A6%8F%E0%A6%B8%E0%A6%BF%E0%A6%86%E0%A6%87%22&hl=bn&gl=BD&ceid=BD:bn')\n",
    "identifier = \"//article\"\n",
    "search_links = driver.find_elements(By.XPATH, identifier + \"/a[@href]\")\n",
    "headlines = driver.find_elements(By.XPATH, identifier + \"/h3\")\n",
    "dates = driver.find_elements(By.XPATH, identifier + '/div/div/time')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'newspaper': 'ntv',\n 'link': 'https://www.ntvbd.com/job-circular/%E0%A6%A2%E0%A6%BE%E0%A6%95%E0%A6%BE%E0%A7%9F-%E0%A6%A8%E0%A6%BF%E0%A7%9F%E0%A7%8B%E0%A6%97-%E0%A6%A6%E0%A7%87%E0%A6%AC%E0%A7%87-%E0%A6%8F%E0%A6%AA%E0%A6%BF%E0%A6%95-%E0%A6%97%E0%A7%8D%E0%A6%B0%E0%A7%81%E0%A6%AA-1160657',\n 'language': 'bn',\n 'date': '2022-12-14',\n 'section': 'চাকরি চাই\\nবিবিধ',\n 'source': 'চাকরি চাই ডেস্ক',\n 'headline': 'ঢাকায় নিয়োগ দেবে এপিক গ্রুপ',\n 'description': 'নিয়োগ বিজ্ঞপ্তি প্রকাশ করেছে এপিক গ্রুপ। প্রতিষ্ঠানটিতে ‘সিনিয়র এক্সিকিউটিভ-কম্প্লায়েন্স’ পদে নিয়োগ দেওয়া হবে। আগ্রহী যোগ্য প্রার্থীরা আবেদন করতে পারবেন।\\n\\n\\n\\n\\nপদের নাম\\n\\n\\n\\n\\nসিনিয়র এক্সিকিউটিভ-কমপ্লায়েন্স।\\nশিক্ষাগত যোগ্যতা ও অভিজ্ঞতা\\nযেকানো বিষযে স্নাতক পাস প্রার্থীরা আবেদন করতে পারবেন। বয়স ২৫ থেকে ৪০ বছর। নারী প্রার্থীরা আবেদন করতে পারবেন। পরিসংখ্যান ব্যাকগ্রাউন্ডের প্রার্থীরা সুবিধা পাবেন। এক্সেল ফর্মূলা, ডাটা ভিজ্যুয়ালাইজেশন, পাওয়ার পয়েন্ট এবং বাংলা টাইপিং দক্ষতা ইত্যাদিসহ কম্পিউটার সাক্ষরতায় খুব ভালো। ভালো বিশ্লেষণী ক্ষমতা। সম্মতি সমন্বয় এবং ডাটা এনালিস্ট হিসাবে কাজ করা।\\nকর্মস্থল\\nঢাকা।\\nবেতন\\nআলোচনা সাপেক্ষে।\\nআবেদনের পদ্ধতি\\nপ্রার্থী বিডিজবস অনলাইনে আবেদন করতে পারবেন।\\nআবেদনের শেষ তারিখ\\n১৭ ডিসেম্বর, ২০২২।\\nসূত্র : বিডিজবস'}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import chromedriver_autoinstaller\n",
    "chromedriver_autoinstaller.install()\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"start-maximized\")\n",
    "search_key=\"এসিআই\"\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get('https://www.prothomalo.com/' + \"search?q=\" + search_key)\n",
    "# search_links = driver.find_elements(By.XPATH, \"//a[@class='card-with-image-zoom'][@href]\")\n",
    "next_j = 0\n",
    "keep_content = True\n",
    "# for j, element in enumerate(search_links[next_j:]):\n",
    "link = \"https://www.ntvbd.com/job-circular/%E0%A6%A2%E0%A6%BE%E0%A6%95%E0%A6%BE%E0%A7%9F-%E0%A6%A8%E0%A6%BF%E0%A7%9F%E0%A7%8B%E0%A6%97-%E0%A6%A6%E0%A7%87%E0%A6%AC%E0%A7%87-%E0%A6%8F%E0%A6%AA%E0%A6%BF%E0%A6%95-%E0%A6%97%E0%A7%8D%E0%A6%B0%E0%A7%81%E0%A6%AA-1160657\"\n",
    "# print(f\"News number: {next_j + (j + 1)}\")\n",
    "page_source = requests.get(link).text\n",
    "page_html = BeautifulSoup(page_source, features=\"html.parser\")\n",
    "date = page_html.find('meta', {'property': re.compile(r'time')})\n",
    "headline = page_html.find('h1', {'itemprop': re.compile(r'headline')})\n",
    "section = page_html.find('nav', {'role': re.compile(r\"navigation\")})\n",
    "source = page_html.find('div', {'class': re.compile(r\"author\")})\n",
    "try:\n",
    "    data_dict = {\n",
    "        'newspaper': 'ntv',\n",
    "        'link': link,\n",
    "        'language': 'bn',\n",
    "        'date': str(pd.to_datetime(date['content']).date()) if date else '',\n",
    "        'section': section.text.strip() if section else '',\n",
    "        'source': source.text.strip() if source else '',\n",
    "        'headline': headline.text.strip()\n",
    "    }\n",
    "    if keep_content:\n",
    "        description = page_html.find('div', {'class': re.compile(r\"^section-content\")})\n",
    "        data_dict['description'] = description.text.strip() if description else description\n",
    "except:\n",
    "    print(\"Error in extracting information or advertisement error.\")\n",
    "data_dict\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "# page_source = requests.get(page_link).text\n",
    "# page_html = BeautifulSoup(page_source, features=\"html.parser\")\n",
    "# date = page_html.find('time', {'datetime': re.compile(r\"\")})['datetime']\n",
    "# page_header = page_html.find('div', {'class': re.compile(r\"story-title\")})\n",
    "# headline = page_header.find('h1')\n",
    "# section = page_header.find('a')\n",
    "# source = page_html.find('div', {'class': re.compile(r\"contributor\")})\n",
    "# location = page_html.find('span', {'class': re.compile(r\"location\")})\n",
    "#\n",
    "# if keep_content:\n",
    "#     description = page_html.find('div', {'class': re.compile(r\"^story-grid\")})\n",
    "#\n",
    "#\n",
    "# data_dict = {\n",
    "#     'newspaper': 'prothomalo',\n",
    "#     'link': page_link,\n",
    "#     'language': 'bn',\n",
    "#     'date': str(pd.to_datetime(date).date()) if date else None,\n",
    "#     'section': section.attrs['aria-label'].strip() if section else '',\n",
    "#     'source': ''.join([source.text if source else ''] + [', ' + location.text if location else '']),\n",
    "#     'headline': headline.text.strip()\n",
    "# }\n",
    "# if keep_content:\n",
    "#     desc = ''\n",
    "#     for para in description.find_all('p'):\n",
    "#         desc += para.text + '\\n'\n",
    "#     data_dict['description'] = desc if description else description\n",
    "#\n",
    "# print(data_dict)\n",
    "# translate = True\n",
    "# news_data_df = pd.DataFrame()\n",
    "# for name in names[0:1]:\n",
    "#     news_df = get_news.extract(name, google_news=False, keep_content=False)\n",
    "#     if translate: news_df = get_news.translate_news(news_df)\n",
    "#     news_df['sentiment'] = get_sentiment(news_df.headline.to_list())\n",
    "#     news_data_df = pd.concat((news_data_df, news_df), axis=0, ignore_index=True)\n",
    "#\n",
    "# get_news.close_browser()\n",
    "# news_data_df.to_csv(\"./outputs.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "<div class=\"author-name-location-wrapper\"><div class=\"print-authors-list zM7oX\"><div class=\"contributor-type-7 wqvPE _7cKay\"><span class=\"contributor-name _8TSJC\">তারিকুর রহমান খান</span></div></div></div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_html.find('div', {'class': re.compile(r\"location\")}).find()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.read_csv(\"./ntv.csv\")\n",
    "df1 = pd.read_csv(\"./prothomalo.csv\")\n",
    "df3 = pd.read_csv(\"./kalerkantho.csv\")\n",
    "df4 = pd.read_csv(\"./data/temp1.csv\")\n",
    "all_news = pd.concat((df1, df2, df3, df4), axis=0, ignore_index=True)\n",
    "all_news.to_csv(\"./data/final_runthis.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n"
     ]
    },
    {
     "data": {
      "text/plain": "<pandasgui.gui.PandasGui at 0x24da52664c0>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandasgui import show\n",
    "all_news = pd.read_csv(\"./data/final_runthis.csv\")\n",
    "show(all_news)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/temp.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m temp_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./data/temp.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m show(temp_df)\n",
      "File \u001B[1;32mc:\\users\\public\\aci_proj\\projects\\bd-newspaper-scrapper\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[1;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mc:\\users\\public\\aci_proj\\projects\\bd-newspaper-scrapper\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[0;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[0;32m    330\u001B[0m     )\n\u001B[1;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mc:\\users\\public\\aci_proj\\projects\\bd-newspaper-scrapper\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    936\u001B[0m     dialect,\n\u001B[0;32m    937\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    946\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    947\u001B[0m )\n\u001B[0;32m    948\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 950\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\public\\aci_proj\\projects\\bd-newspaper-scrapper\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    602\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    604\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 605\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32mc:\\users\\public\\aci_proj\\projects\\bd-newspaper-scrapper\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1439\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1441\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1442\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\public\\aci_proj\\projects\\bd-newspaper-scrapper\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1733\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1734\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1735\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1736\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1737\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1738\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1739\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1740\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1741\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1742\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1743\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1744\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32mc:\\users\\public\\aci_proj\\projects\\bd-newspaper-scrapper\\venv\\lib\\site-packages\\pandas\\io\\common.py:856\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    851\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    852\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    853\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    854\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    855\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 856\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    857\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    858\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    859\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    861\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    863\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    864\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    865\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './data/temp.csv'"
     ]
    }
   ],
   "source": [
    "temp_df = pd.read_csv(\"./data/temp.csv\")\n",
    "show(temp_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/sentiment_news.csv\")\n",
    "map_dict = {0: 'NEG', 1: 'NEU', 2: 'POS'}\n",
    "df[\"sentiment\"] = df['sentiment'].map(map_dict)\n",
    "df.to_csv(\"./data/sentiment_news.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "               newspaper                                link language  \\\n0                    ntv               https://www.ntvbd.com   bangla   \n1                    ntv               https://www.ntvbd.com   bangla   \n2                    ntv               https://www.ntvbd.com   bangla   \n3                    ntv               https://www.ntvbd.com   bangla   \n4             prothomalo          https://www.prothomalo.com   bangla   \n..                   ...                                 ...      ...   \n252  thefinancialexpress  https://thefinancialexpress.com.bd  english   \n253  thefinancialexpress  https://thefinancialexpress.com.bd  english   \n254  thefinancialexpress  https://thefinancialexpress.com.bd  english   \n255  thefinancialexpress  https://thefinancialexpress.com.bd  english   \n256  thefinancialexpress  https://thefinancialexpress.com.bd  english   \n\n                          date  \\\n0    2022-08-21 07:00:00+00:00   \n1    2022-11-16 08:55:00+00:00   \n2    2022-10-15 07:00:00+00:00   \n3    2022-06-29 07:00:00+00:00   \n4    2022-09-01 08:00:00+00:00   \n..                         ...   \n252  2022-06-25 07:00:00+00:00   \n253  2022-05-21 07:00:00+00:00   \n254  2022-10-13 07:00:00+00:00   \n255  2021-11-15 08:00:00+00:00   \n256  2022-01-15 08:00:00+00:00   \n\n                                              headline sentiment  \n0                     ACI will hire without experience       NEG  \n1                                Build a career at ACI       NEU  \n2                        ACI will recruit in Sirajganj       NEU  \n3                   ACI will provide jobs in Sirajganj       NEU  \n4    ACI Motors: A combination of state-of-the-art ...       NEU  \n..                                                 ...       ...  \n252                     Rice, vegetable prices on rise       NEG  \n253                 JulyApril pharma export soars 27pc       POS  \n254  Hyundai passenger vehicle production begins sh...       NEU  \n255  Yamaha launches new scooter Street Rally 125cc...       NEU  \n256        Shwapno inaugurates new outlet in Dhanmondi       NEU  \n\n[257 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>newspaper</th>\n      <th>link</th>\n      <th>language</th>\n      <th>date</th>\n      <th>headline</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ntv</td>\n      <td>https://www.ntvbd.com</td>\n      <td>bangla</td>\n      <td>2022-08-21 07:00:00+00:00</td>\n      <td>ACI will hire without experience</td>\n      <td>NEG</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ntv</td>\n      <td>https://www.ntvbd.com</td>\n      <td>bangla</td>\n      <td>2022-11-16 08:55:00+00:00</td>\n      <td>Build a career at ACI</td>\n      <td>NEU</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ntv</td>\n      <td>https://www.ntvbd.com</td>\n      <td>bangla</td>\n      <td>2022-10-15 07:00:00+00:00</td>\n      <td>ACI will recruit in Sirajganj</td>\n      <td>NEU</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ntv</td>\n      <td>https://www.ntvbd.com</td>\n      <td>bangla</td>\n      <td>2022-06-29 07:00:00+00:00</td>\n      <td>ACI will provide jobs in Sirajganj</td>\n      <td>NEU</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>prothomalo</td>\n      <td>https://www.prothomalo.com</td>\n      <td>bangla</td>\n      <td>2022-09-01 08:00:00+00:00</td>\n      <td>ACI Motors: A combination of state-of-the-art ...</td>\n      <td>NEU</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>252</th>\n      <td>thefinancialexpress</td>\n      <td>https://thefinancialexpress.com.bd</td>\n      <td>english</td>\n      <td>2022-06-25 07:00:00+00:00</td>\n      <td>Rice, vegetable prices on rise</td>\n      <td>NEG</td>\n    </tr>\n    <tr>\n      <th>253</th>\n      <td>thefinancialexpress</td>\n      <td>https://thefinancialexpress.com.bd</td>\n      <td>english</td>\n      <td>2022-05-21 07:00:00+00:00</td>\n      <td>JulyApril pharma export soars 27pc</td>\n      <td>POS</td>\n    </tr>\n    <tr>\n      <th>254</th>\n      <td>thefinancialexpress</td>\n      <td>https://thefinancialexpress.com.bd</td>\n      <td>english</td>\n      <td>2022-10-13 07:00:00+00:00</td>\n      <td>Hyundai passenger vehicle production begins sh...</td>\n      <td>NEU</td>\n    </tr>\n    <tr>\n      <th>255</th>\n      <td>thefinancialexpress</td>\n      <td>https://thefinancialexpress.com.bd</td>\n      <td>english</td>\n      <td>2021-11-15 08:00:00+00:00</td>\n      <td>Yamaha launches new scooter Street Rally 125cc...</td>\n      <td>NEU</td>\n    </tr>\n    <tr>\n      <th>256</th>\n      <td>thefinancialexpress</td>\n      <td>https://thefinancialexpress.com.bd</td>\n      <td>english</td>\n      <td>2022-01-15 08:00:00+00:00</td>\n      <td>Shwapno inaugurates new outlet in Dhanmondi</td>\n      <td>NEU</td>\n    </tr>\n  </tbody>\n</table>\n<p>257 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/sentiment_news.csv\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n"
     ]
    },
    {
     "data": {
      "text/plain": "<pandasgui.gui.PandasGui at 0x225d41c1160>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandasgui as pg\n",
    "df = pd.read_csv(\"./data/temp1.csv\")\n",
    "pg.show(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'The voice of time'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deep_translator import (GoogleTranslator, single_detection)\n",
    "my_api = \"15c5418e83130ba091ea4d07875a7517\"\n",
    "# trans_b2e = GoogleTranslator(source='bn', target='en')\n",
    "bn2en = GoogleTranslator(source='bn', target='en')\n",
    "\n",
    "\n",
    "bn2en.translate(\"কালের কণ্ঠ\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}