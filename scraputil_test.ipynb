{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/shadman/.local/lib/python3.8/site-packages/gensim/matutils.py:22: DeprecationWarning: Please use `triu` from the `scipy.linalg` namespace, the `scipy.linalg.special_matrices` namespace is deprecated.\n",
      "  from scipy.linalg.special_matrices import triu\n",
      "/home/shadman/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: HIP initialization: Unexpected error from hipGetDeviceCount(). Did you run some cuda functions before calling NumHipDevices() that might have already set an error? Error 101: hipErrorInvalidDevice (Triggered internally at  ../c10/hip/HIPFunctions.cpp:110.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2022-11-13 12:29:40.736101: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-13 12:29:41.000518: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-13 12:29:41.059320: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-13 12:29:41.059341: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-13 12:29:41.096245: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-13 12:29:41.871865: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-13 12:29:41.871931: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-13 12:29:41.871935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-13 12:29:42.517368: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-13 12:29:42.517626: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-13 12:29:42.517643: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (HP-ProBook-27516): /proc/driver/nvidia/version does not exist\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/shadman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from scraputil import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping from Dhaka Tribune\n",
      "Searching...\n",
      "Search results ready!!\n",
      "News number: 1\n",
      "News number: 2\n",
      "News number: 3\n",
      "News number: 4\n",
      "News number: 5\n",
      "News number: 6\n",
      "News number: 7\n",
      "News number: 8\n",
      "News number: 9\n",
      "News number: 10\n",
      "1\n",
      "End of Dhaka Tribune search!\n",
      "0 GPU available\n",
      "Model already on device!\n",
      "Scraping from The Business Standard\n",
      "Searching...\n",
      "Search results ready!!\n",
      "News number: 1\n",
      "News number: 2\n",
      "News number: 3\n",
      "News number: 4\n",
      "News number: 5\n",
      "News number: 6\n",
      "News number: 7\n",
      "News number: 8\n",
      "News number: 9\n",
      "News number: 10\n",
      "1\n",
      "End of The Business Standard search!\n",
      "0 GPU available\n",
      "Model already on device!\n"
     ]
    }
   ],
   "source": [
    "names = [ # 'newspapers71',\n",
    "         'ntv',\n",
    "         'prothomalo',\n",
    "         'kalerkantho',\n",
    "         'bhorerkagoj',\n",
    "         'jaijaidin',\n",
    "         # 'amadershomoy',\n",
    "         'inqilab',\n",
    "         'jugantor',\n",
    "         'nayadiganta',\n",
    "         'manabzamin',\n",
    "         'thedailystar',\n",
    "         'dhakatribune',\n",
    "         'tbsnews',\n",
    "         'thefinancialexpress']\n",
    "\n",
    "get_news = GetNews(browser=\"Firefox\", headless=False, search_key=\"এসিআই\")\n",
    "get_news.select_browser(\"Firefox\")\n",
    "\n",
    "translate = True\n",
    "news_data_df = pd.DataFrame()\n",
    "for name in names[-3:-1]:\n",
    "    news_df = get_news.extract(name, google_news=False, keep_content=True)\n",
    "    if translate: news_df = get_news.translate_news(news_df)\n",
    "    news_df['sentiment'] = get_sentiment(news_df.headline.to_list())\n",
    "    news_data_df = pd.concat((news_data_df, news_df), axis=0, ignore_index=True)\n",
    "\n",
    "get_news.close_browser()\n",
    "news_data_df.to_csv(\"./outputs.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# get_news.driver.close()\n",
    "get_news = GetNews(browser=\"Chrome\", headless=False, search_key=\"এসিআই\")\n",
    "# get_news.set_browser_options(\"Chrome\")\n",
    "get_news.select_browser(\"Chrome\")\n",
    "driver = get_news.driver\n",
    "driver.get(\"https://thefinancialexpress.com.bd/search?term=news&query=ACI&page=1\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching...\n",
      "Search results ready!!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Searching...\")\n",
    "    WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//div[@class='container']/div/a[@class='local-news'][@href]\")))\n",
    "    print(\"Search results ready!!\")\n",
    "except TimeoutException:\n",
    "    print(\"Timed out!\")\n",
    "\n",
    "search_links = driver.find_elements(By.XPATH, \"//div[@class='container']/div/a[@class='local-news'][@href]\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "scrap_df = []\n",
    "i = 1\n",
    "while i <= pages:\n",
    "    try:\n",
    "        print(\"Searching...\")\n",
    "        WebDriverWait(self.driver, 5).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//div[@class='gs-title']/a[@class ='gs-title'][@href]\")))\n",
    "        print(\"Search results ready!!\")\n",
    "    except TimeoutException:\n",
    "        print(\"Timed out!\")\n",
    "\n",
    "    search_links = self.driver.find_elements(By.XPATH, \"//div[@class='gs-title']/a[@class='gs-title'][@href]\")\n",
    "    j = 1\n",
    "    for j, element in enumerate(search_links):\n",
    "        page_link = element.get_attribute(\"href\")\n",
    "        print(f\"News number: {(i - 1) * len(search_links) + (j + 1)}\")\n",
    "\n",
    "        page_dict = scan_page_tbs(page_link, keep_content=keep_content)\n",
    "        scrap_df.append(page_dict)\n",
    "\n",
    "    # Go to next page\n",
    "    try:\n",
    "        print(i)\n",
    "        next_page = WebDriverWait(self.driver, 10).until(EC.element_to_be_clickable(\n",
    "            (By.XPATH, f\"//ul[@class='pagination']/li/a[@href]']\")))\n",
    "        next_page.click()\n",
    "\n",
    "    except ElementClickInterceptedException:\n",
    "        print(\"Element not visible due to ad\")\n",
    "        next_page_element = WebDriverWait(self.driver, 5).until(EC.visibility_of_element_located(\n",
    "            (By.XPATH, f\"//div[@class='gsc-cursor']/div[@aria-label='Page {i + 1}']\")))\n",
    "        self.driver.execute_script(\"return arguments[0].scrollIntoView(true);\", next_page_element)\n",
    "        self.driver.find_element(By.XPATH,\n",
    "                                 f\"//div[@class='gsc-cursor']/div[@aria-label='Page {i + 1}']\").click()\n",
    "    except:\n",
    "        print(\"Scraping done!\")\n",
    "        break\n",
    "    i += 1\n",
    "    sleep(2)\n",
    "\n",
    "print(\"End of The Business Standard search!\")\n",
    "scrap_df = pd.DataFrame(scrap_df)\n",
    "return scrap_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16228/3360014758.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.name[2] = 5\n"
     ]
    }
   ],
   "source": [
    "df.name[2] = 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
